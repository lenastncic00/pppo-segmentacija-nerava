{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lenastncic00/pppo-segmentacija-nerava/blob/main/it50_2018_stan%C4%8Di%C4%87_lena_segmentacija.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH1yj6bs6asq"
      },
      "source": [
        "**Univerzitet u Novom Sadu**\n",
        "\n",
        "**Fakultet tehniƒçkih nauka**\n",
        "\n",
        "**Departman za industrijsko in≈æenjerstvo i menad≈æment**\n",
        "\n",
        "**In≈æenjerstvo informacionih sistema**\n",
        "\n",
        "**Predmet:** *Principi prezentacije i prepoznavanja oblika*\n",
        "\n",
        "**Tema:** *Segmentacija*\n",
        "\n",
        "**Student:** *Lena Stanƒçiƒá IT50/2018*\n",
        "\n",
        "**Datum:** *Jul 2022*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUCQwiTyc1L7"
      },
      "source": [
        "**Uvod**\n",
        "\n",
        "Za izradu projektnog zadatka dobijen je set podataka koji sadr≈æi ultrazvuƒçne slike nerava ljudskog tela na kojim je potrebno identifikovati nervne strukture. Tema koju je bilo potrebno odraditi za ovaj projekat na predmetu Principi prezentacije i prepoznavanja oblika je segmentacija. Projekat je planiran da bude predstavljen u dva dela teoretski i praktiƒçan deo.\n",
        "\n",
        "Izrada projekta se sastoji od uƒçitavanja podataka, vizuelizacije, izrade modela, treniranja, evaluacije i testiranja.\n",
        "\n",
        "**Segmentacija**\n",
        "\n",
        "Razvoje tehnologije u okviru medicinskog podruƒçja pru≈æilo je ogromne napredke o kojima se nikada ranije nije moglo ni pretpostaviti. Uƒçinjena su mnoga pobolj≈°anja na polju hirurgije, medicine, rendgenskih zraka i mnogih drugih. Iz prilo≈æenog, slike se dele u odgovarajuƒáe piksele tj. dele se na osnovu odreƒëenog podruƒçja ili kategorije ≈°to znatno poma≈æe medicinskom osoblju u br≈æem i kvalitetnijem otkrivanju anomalija na pomenutim snimcima.\n",
        "\n",
        "U digitalnoj obradi slike, segmentacija predstavlja proces podjele slike na vi≈°e segmenata tj. razinstance.pngsemantic.pngliƒçitih regiona ili kategorija. Kako segment predstavlja skup piksela, svaka regija sadr≈æi piksele sa sliƒçnim atributima, a svaki piksel na slici se dodjeljuje jednoj kategoriji. Stoga, segmentacija slike predstavlja postupak dodjeljivanja oznake svakom pikselu na slici tako da pikseli sa istom oznakom dijele odreƒëene karakteristike. [1]\n",
        "\n",
        "Cilj segmentacije nerava je pobolj≈°anje tretmana zasnovanih na ultrazvuƒçnim snimcima koji se ≈°iroko koriste u medicini zbog velikog podruƒçja primene i ekonomiƒçnosti. Jedan od nedostataka ovih slika je ≈°to sadr≈æe ogromnu koliƒçinu buke, tako da se medicinsko osoblje suoƒçava sa pote≈°kocÃÅama u pronala≈æenju taƒçnog mesta nerva. PomocÃÅu segmentacije nerava na ultrazvuƒçnim slikama vrlo lako se mogu pronacÃÅi nervi.\n",
        "\n",
        "**Metode segmentacije**\n",
        "\n",
        "U literaturi se mogu naƒái razliƒçite podele kada su u pitanju tehnike koje se primjenjuju prilikom segmentacije. Osnovna podela je na dve najƒçe≈°ƒáe kori≈°ƒáene tehnike:\n",
        "\n",
        "Pronala≈æenje ivica ili segmentacija instance ‚Äì izdvajanje samo onih piksela koji pripadaju rubovima objekata i\n",
        "Izdvajanje regiona ili semantiƒçka segmentacija ‚Äì izdvajanje celog objekta od pozadine pridru≈æujuƒái piksele ƒçija je svetlost ispod nekog praga pozadini, a ostale objektu i obrnuto.\n",
        "\n",
        "\n",
        "**Algoritmi i tehnike za segmentaciju**\n",
        "\n",
        "Postoje razliƒçite podele algoritama i tehnika za segmentaciju u zavisnosti od autora ali najveƒái broj njih vidi sledeƒáe ƒçetiri tehnike koje se koriste:\n",
        "\n",
        "1.  Segmentacija pragom (Thresholding)\n",
        "2.  Segmentacija klasterizacijom (Clustering)\n",
        "3.  Segmentacija regionom (Region)\n",
        "4.  Segmentacija granicom regiona (Edge)\n",
        "\n",
        " \n",
        "\n",
        "*   **Segmentacija pragom** predstavlja grupu metoda zasnovanih na poreƒëenju osvetljenosti piksela sa jednim ili vi≈°e pragova, pa tako imamo segmentaciju sa jednim i segmentaciju sa vi≈°e pragova. Ukoliko imamo slike u boji tada se vr≈°i poreƒëenje boje izmeƒëu piksela. Segmentacija sa jednim pragom predstavlja najjednostavniji vid segmentacije i njegova osnovna primena je za odvajanje objekta od pozadine, ukoliko pozadina ima uniformnu osvjetljenost (boju) koja se razlikuje od objekta. Ovakav naƒçin segmentacije se mo≈æe primjeniti, npr., kod izdvajanja pisanog ili ≈°tampanog teksta, analize nekih biomedicinskih slika, prepoznavanja tipa aviona koji leti, itd. Segmentacija sa vi≈°e pragova je metoda koju je pogodno koristiti u sluƒçaju kada imamo scene sa vi≈°e razliƒçitih objekata.\n",
        "*   **Segmentacija klasterizacijom** je jedna od najstarijih tehnika segmentacije, s obzirom da se mo≈æe koristiti za segmentaciju sivih i slika u boji. Za vektor x=[x1, x2,‚Ä¶,xN] koji predstavlja merenja karakteristika jednog piksela slike, merene veliƒçine mogu biti tri komponente boje piksela, ili neka druga obele≈æja izraƒçunata u malom prozoru oko posmatranog piksela. Postupak segmentacije se u tom sluƒçaju sastoji od podele N‚Äìdimenzionalnog prostora u uzajamno iskljuƒçive oblasti, pri ƒçemu svaka ta oblast obuhvata grupu podataka koja se odnosi na jedan region slike. Takav proces podele prema sliƒçnosti vektora podataka se naziva klasterizacija. U prvoj fazi segmentacije vr≈°i se izraƒçunavanje i izdvajanje nekih obele≈æja slike. Sledeƒáa faza podrazumijeva odreƒëivanje optimalnog broja regiona (klastera), kao i odreƒëivanje skupa vektora koji predstavljaju centre svakog klastera. Nakon toga se vr≈°i pridru≈æivanje svakog piksela jednom od klastera. Pridru≈æivanje se vr≈°i na osnovu sliƒçnosti vektora koji opisuje piksel i vektora koji opisuje centar klastera. Ova metoda je sa dosta uspeha primenjivana u segmentaciji multispektralnih satelitskih ili avionskih snimaka, gdje je osnovni cilj bio izdvajanje regiona na povr≈°ini zemlje koji imaju iste karakteristike, kao ≈°to su npr., isti tip poljoprivrednih kultura, isti sastav zemlji≈°ta, ista nadmorska visina, itd. Nedostatak ove metode je ≈°to ima veliku raƒçunsku slo≈æenost.\n",
        "\n",
        "* **Segmentacija regionom** predstavlja skup metoda koje poku≈°avaju da izdvoje podruƒçja slike koja su homogena sa gledi≈°ta odreƒëenih karakteristika. U ovu grupu spadaju:\n",
        "\n",
        "  1.   Segmentacija pomoƒáu rasta regiona\n",
        "  2.   Segmentacija pomoƒáu razdvajanja i spajanja regiona\n",
        "\n",
        "  * Osnovna ideja **segmentacije pomoƒáu rasta regiona** je da se izvr≈°i grupisanje susednih piksela sliƒçnih osvetljenosti (boja), na osnovu ƒçega se formiraju regioni. Postupak grupisanja poƒçinje spajanjem po dva piksela istih karakteristika, pri ƒçemu nastaje atomski region. Nakon toga se posmatraju dva susedna regiona R1 i R2, ƒçiji su obimi (broj iviƒçnih piksela) oznaƒçeni sa P1 i P2. Neka C predstavlja du≈æinu zajedniƒçke granice regiona, a D du≈æinu zajedniƒçke granice gde je razlika izmeƒëu karakteristika piksela sa obe strane granice manja od unapred definisane vrednosti. Ka≈æemo da ƒáe se regioni R1 i R2 spojiti ukoliko va≈æi: ùê∑ ùëöùëñùëõ(ùëÉ1,ùëÉ2,) > Œµ2 gde je Œµ2 konstanta ƒçija je vrednost najƒçe≈°ƒáe jednaka 0.5. Zatim se vr≈°i ispitivanje ostalih atomskih regiona, nakon ƒçega se prelazi na ispitivanje regiona veƒáih dimenzija sve dok je spajanje moguƒáe. Metoda rasta regiona je naroƒçito pogodna kod segmentacije prostih scena sa malim brojem objekata i slabom teksturom.\n",
        "\n",
        "  * Kod **segmentacije pomoƒáu razdvajanja i spajanja regiona**, slika se deli na ƒçetiri kvadranta, nakon ƒçega se ispituje da li su dobijeni podsegmenti uniformni po obele≈æju na osnovu kojeg se vr≈°i segmentacija. Uniformnost se mo≈æe definisati kao razlika izmeƒëu najmanje i najveƒáe osvetljenosti piksela u regionu, preko varijanse osvetljenosti ili preko neke druge statistiƒçke mere. Svaki podsegment, za koji nije zadovoljen uslov uniformnosti, se dalje deli na ƒçetiri nova podsegmenta. Nakon ≈°to se izvr≈°i razdvajanje, prelazi se na obrnuti postupak ‚Äì spajanje regiona. Regioni koji imaju isto uniformno obele≈æje spajaju se u veƒái region. Nedostatak ove metode je u tome ≈°to se javlja vidljiva blokovska struktura regiona.\n",
        "* U procesu **segmentacije koji koristi ivice (granice regiona)** mora se primeniti i neki postupak za spajanje ivica, kako bi se formirale neprekidne granice regiona iz razloga ≈°to metode koje vr≈°e izdvajanje ivica generi≈°u isprekidane granice objekata a ne zatvorene krive. U tu svrhu se mogu koristiti: metoda spajanja ivica fitovanjem krive, spajanje ivica heuristiƒçkim metodama i spajanje ivica Hafovom transformacijom. Metodom fitovanja krivih se mogu rekonstruisati nedostajuƒái segmenti ukoliko mapa ivica sadr≈æi prekinute ivice. Fitovanje krivih je najjednostavnije kada nam je poznat oblik krive, pa se nedostajuƒái segment dobija fitovanjem npr. pravih ili kru≈ænih oblika. Kada su granice regiona slo≈æenije, vr≈°i se razlaganje granice na jednostavnije delove. Glavna prednost ovog metoda je njena izuzetna jednostavnost i ona daje dobre rezultate u sluƒçaju segmentacije jednostavnih scena. Meƒëutim, kada imamo slike na kojima postoji veƒái broj objekata koji se preklapaju, mapa ivica sadr≈æi taƒçke grananja, pa u tom sluƒçaju ova metoda ne daje dobre rezultate. Kod heuristiƒçkih metoda za spajanje ivica se prvo formira gradijentna slika primenom odgovarajuƒáih maski.\n",
        "\n",
        "**Projektni zadatak**\n",
        "\n",
        "Zadatak je da se na ultrazvuƒçnim slikama segmentira skup nerava.\n",
        "\n",
        "Dobijeni dataset se sastoji od:\n",
        "\n",
        "1. train foldera koji sadr≈æi slike koje se koriste za treniranje modela. Ova mapa ukljuƒçuje slike maski koje prikazuju segmentaciju. Dakle, za svaku sliku svake osobe imamo odgovarajuƒáu masku koja pokazuje da li ima identifikovanih nerava ili ne.\n",
        "\n",
        "2. test foldera koji sadr≈æi slike za testiranje modela. Cilj je predvideti segmentaciju za ove slike i na njima nije dat broj osobe na koju se odnose, kako model sam treba da vr≈°i procenu. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Zakljuƒçak**\n",
        "Cilj projekta je bio da se na najefikasniji naƒçin pribli≈æi koncept segmentacije kao jedna od tehnika dubokog uƒçenja.\n",
        "Tema je vrlo zanimljiva, jer omoguƒáava uvid u realni problem i naƒçin na koji tehnologija mo≈æe da da doprinos re≈°avanju istog.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Reference**\n",
        "\n",
        "[1] Linda G. Shapiro, George C. Stockman. Computer Vision. New Jersey. Prentice-Hall (2001)\n",
        "\n",
        "[2] Yi Jingru, Wu Pengxiang, Jiang Menglin, Huang Qiaoying, Hoeppner J. Daniel, Metaxas N. Dimitris. Attentive neural cell instance segmentation. Medical Image Analysis (2019)\n",
        "\n",
        "[3] Guo Dazhou, Pei Yanting, Zheng Kang, Yu Hongkai, Lu Yuhang, Wang Song. Degraded Image Semantic Segmentation With Dense-Gram Networks. IEEE Transactions on Image Processing (2020)\n",
        "\n",
        "[4] Umbaugh E. Scott. Digital image processing and analysis: Human and computer vision Applications with CVIPtools (2nd). Boca Raton, FL. CRC Press (2010)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Bibliotke u projektu**\n",
        "\n",
        "Na poƒçetku projekta potrebno je instalirati odgovarajuƒáe biblioteke koje su neophodne za samu realizaciju.Jedna od  biblioteka je (segmentation_models_pytorch albumentations) zasnovana je na PyTorch-u. To je biblioteka koja se koristi za deep learning aplikacije koje koriste GPU ili CPU.Takoƒëe. Hardware acceleration za izradu ovog projekta pode≈°en je na GPU.\n",
        "\n",
        "Podesiti: runtime type Runtime->Change runtime type->(Hardware accelerator=GPU).\n",
        " \n",
        "Hardversko ubrzanje predstavlja proces kojim ƒáe aplikacija rasteretiri odreƒëene raƒçunarske zadatke na specijalizovane hardverske komponente u sistemu i na taj naƒçin ƒáe se omoguƒáiti veƒáa efikasnost nego ≈°to je to moguƒáe u softveru koji radi samo na CPU op≈°te namene.\n",
        "\n",
        "Druga instalacija odnosi se na instalaciju albumentations biblioteke. To je Python biblioteka za poveƒáavanje kvaliteta obuƒçenih modela. Svrha poveƒáanja slike je stvaranje novih uzoraka obuke postojeƒáih podataka. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Potrebno je preuzeti skup podataka i raspakovati na lokaciji koja je dodjeljena projektu."
      ],
      "metadata": {
        "id": "POBDwtweGQz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hJiw26U72dn",
        "outputId": "fad58fa7-816c-421d-c5e0-6cc3f9e4111e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-14 21:18:19--  https://docs.google.com/uc?export=download&confirm=t&id=1zAz7WORXnMuOVZSQN_XJFQOLcdrVw3uo\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.148.101, 142.250.148.100, 142.250.148.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.148.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-3c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1c4h61sb1vqnq76gl091ndbh9cor0tan/1657833450000/12749817884604637057/*/1zAz7WORXnMuOVZSQN_XJFQOLcdrVw3uo?e=download&uuid=35545f33-93f5-4933-8e7b-ead06bbcac6c [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-07-14 21:18:19--  https://doc-0g-3c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1c4h61sb1vqnq76gl091ndbh9cor0tan/1657833450000/12749817884604637057/*/1zAz7WORXnMuOVZSQN_XJFQOLcdrVw3uo?e=download&uuid=35545f33-93f5-4933-8e7b-ead06bbcac6c\n",
            "Resolving doc-0g-3c-docs.googleusercontent.com (doc-0g-3c-docs.googleusercontent.com)... 142.250.148.132, 2607:f8b0:4001:c54::84\n",
            "Connecting to doc-0g-3c-docs.googleusercontent.com (doc-0g-3c-docs.googleusercontent.com)|142.250.148.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2265141455 (2.1G) [application/x-zip-compressed]\n",
            "Saving to: ‚Äòimages.zip‚Äô\n",
            "\n",
            "images.zip          100%[===================>]   2.11G   148MB/s    in 18s     \n",
            "\n",
            "2022-07-14 21:18:38 (117 MB/s) - ‚Äòimages.zip‚Äô saved [2265141455/2265141455]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/u/0/uc?id=18_wYRTBTsoJ1mmqYLhwkpDLVTzBY-bVq&export=download' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1zAz7WORXnMuOVZSQN_XJFQOLcdrVw3uo\" -O images.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1HU0EOZJ8_8",
        "outputId": "59193466-3040-4ded-aa28-459af87a8fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  images.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test/1.tif              \n",
            "  inflating: test/10.tif             \n",
            "  inflating: test/100.tif            \n",
            "  inflating: test/1000.tif           \n",
            "  inflating: test/1001.tif           \n",
            "  inflating: test/1002.tif           \n",
            "  inflating: test/1003.tif           \n",
            "  inflating: test/1004.tif           \n",
            "  inflating: test/1005.tif           \n",
            "  inflating: test/1006.tif           \n",
            "  inflating: test/1007.tif           \n",
            "  inflating: test/1008.tif           \n",
            "  inflating: test/1009.tif           \n",
            "  inflating: test/101.tif            \n",
            "  inflating: test/1010.tif           \n",
            "  inflating: test/1011.tif           \n",
            "  inflating: test/1012.tif           \n",
            "  inflating: test/1013.tif           \n",
            "  inflating: test/1014.tif           \n",
            "  inflating: test/1015.tif           \n",
            "  inflating: test/1016.tif           \n",
            "  inflating: test/1017.tif           \n",
            "  inflating: test/1018.tif           \n",
            "  inflating: test/1019.tif           \n",
            "  inflating: test/102.tif            \n",
            "  inflating: test/1020.tif           \n",
            "  inflating: test/1021.tif           \n",
            "  inflating: test/1022.tif           \n",
            "  inflating: test/1023.tif           \n",
            "  inflating: test/1024.tif           \n",
            "  inflating: test/1025.tif           \n",
            "  inflating: test/1026.tif           \n",
            "  inflating: test/1027.tif           \n",
            "  inflating: test/1028.tif           \n",
            "  inflating: test/1029.tif           \n",
            "  inflating: test/103.tif            \n",
            "  inflating: test/1030.tif           \n",
            "  inflating: test/1031.tif           \n",
            "  inflating: test/1032.tif           \n",
            "  inflating: test/1033.tif           \n",
            "  inflating: test/1034.tif           \n",
            "  inflating: test/1035.tif           \n",
            "  inflating: test/1036.tif           \n",
            "  inflating: test/1037.tif           \n",
            "  inflating: test/1038.tif           \n",
            "  inflating: test/1039.tif           \n",
            "  inflating: test/104.tif            \n",
            "  inflating: test/1040.tif           \n",
            "  inflating: test/1041.tif           \n",
            "  inflating: test/1042.tif           \n",
            "  inflating: test/1043.tif           \n",
            "  inflating: test/1044.tif           \n",
            "  inflating: test/1045.tif           \n",
            "  inflating: test/1046.tif           "
          ]
        }
      ],
      "source": [
        "!unzip images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZGv3QjZKiZl"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Bjarten/early-stopping-pytorch.git esp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r3bxP_rgeMg"
      },
      "outputs": [],
      "source": [
        "! pip install segmentation_models_pytorch albumentations\n",
        "! pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon uƒçitanog skupa podataka neophodno je uvesti i biblioteke uz kojih ƒáe se lak≈°e i efikasnije uraditi proejkat. Za ovaj projekat koristi se PyTorch, odnosno torchvision biblioteka koja je namjenjena za raƒçunarsku viziju.\n",
        "Pored toga biƒáe potrebne biblioteke za rad sa slikama, listama i grafiƒçkim prikazima."
      ],
      "metadata": {
        "id": "xNc5-oQGG10W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iwMR9xEKlqc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision \n",
        "from torchvision import transforms\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from esp.pytorchtools import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ1H_Cu3Kwt0"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(self, val_loss, model):\n",
        "    import pickle       \n",
        "    if self.verbose:\n",
        "        self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "    with open(self.path, 'wb') as f:\n",
        "        pickle.dump(model, f) # torch.save(model.state_dict(), self.path)\n",
        "    self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EarlyStopping klasa omoguƒáuje praƒáenje validation loss tokom treniranja modela. Saƒçuvaƒáe checkpoint za model svaki put kada se validation loss smanji."
      ],
      "metadata": {
        "id": "OrClTPo8Hwmg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRW0ZW5-KyyL"
      },
      "outputs": [],
      "source": [
        "EarlyStopping.save_checkpoint = save_checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Radi efikasnijeg snala≈æenja kreiraju se konstante koje predstavljaju putanje prema odgovarajuƒáim fajlovima."
      ],
      "metadata": {
        "id": "YjVplNmWIPj4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajguizkCK1nN"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = 'train'\n",
        "TEST_PATH = 'test'\n",
        "\n",
        "TRAIN_CSV_PATH = 'train_annotation.csv'\n",
        "TEST_PATH = 'test'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon ≈°to smo povezali rute, uƒçitavamo nekoliko fotografije iz dataseta. Prikazaƒáemo prve tri slike i njima odgovarajuƒáe maske u okviru jednog reda."
      ],
      "metadata": {
        "id": "q6VY5U1CI6vu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xju-xkoWK5Ut"
      },
      "outputs": [],
      "source": [
        "image1 = np.array(Image.open(\"train/\"+\"1_1.tif\"))\n",
        "image1_mask = np.array(Image.open(\"train/\"+\"1_1_mask.tif\"))\n",
        "image1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n",
        "\n",
        "image2 = np.array(Image.open(\"train/\"+\"1_2.tif\"))\n",
        "image2_mask = np.array(Image.open(\"train/\"+\"1_2_mask.tif\"))\n",
        "image2_mask = np.ma.masked_where(image2_mask == 0, image2_mask)\n",
        "\n",
        "image3 = np.array(Image.open(\"train/\"+\"1_3.tif\"))\n",
        "image3_mask = np.array(Image.open(\"train/\"+\"1_3_mask.tif\"))\n",
        "image3_mask = np.ma.masked_where(image3_mask == 0, image3_mask)\n",
        "\n",
        "fig, ax = plt.subplots(1,9,figsize = (16,12))\n",
        "ax[0].imshow(image1, cmap = 'gray')\n",
        "\n",
        "ax[1].imshow(image1_mask, cmap = 'gray')\n",
        "\n",
        "ax[2].imshow(image1, cmap = 'gray', interpolation = 'none')\n",
        "ax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)\n",
        "\n",
        "ax[3].imshow(image2, cmap = 'gray')\n",
        "\n",
        "ax[4].imshow(image2_mask, cmap = 'gray')\n",
        "\n",
        "ax[5].imshow(image2, cmap = 'gray', interpolation = 'none')\n",
        "ax[5].imshow(image2_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)\n",
        "\n",
        "ax[6].imshow(image3, cmap = 'gray')\n",
        "\n",
        "ax[7].imshow(image3_mask, cmap = 'gray')\n",
        "\n",
        "ax[8].imshow(image3, cmap = 'gray', interpolation = 'none')\n",
        "ax[8].imshow(image3_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8otnOAaPtN7Z"
      },
      "outputs": [],
      "source": [
        "def create_csv(data_path, out_csv_path, key_word='mask'):\n",
        "    to_delete = f'_{key_word}'\n",
        "\n",
        "    for file_name in os.listdir(data_path):\n",
        "        if key_word in file_name:\n",
        "            img = file_name.replace(to_delete, '')\n",
        "            data = pd.DataFrame([img], index=['img']).transpose()\n",
        "            data.insert(0, 'mask', file_name)\n",
        "\n",
        "        else:                \n",
        "            if not os.path.exists(out_csv_path):\n",
        "                data.to_csv(out_csv_path, header=True, index=False)\n",
        "            else:\n",
        "                data.to_csv(out_csv_path, mode='a', header=False, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kreiranje fajla u kojem je upisana matrica sa slikama i njihovim odgovarajuƒáim maskama."
      ],
      "metadata": {
        "id": "ld5QkJErJLZs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkC0WgTbtVIg"
      },
      "outputs": [],
      "source": [
        "create_csv(data_path=TRAIN_PATH, out_csv_path=TRAIN_CSV_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pravljenje Dataseta za model, sme≈°tanje uƒçitanih slika za trening i maski za trening."
      ],
      "metadata": {
        "id": "fLBED-8hJT_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZzRaxz-th35"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "       \n",
        "        mask = Image.open(os.path.join(self.root_dir, self.df.iloc[idx, 0]))\n",
        "        image = Image.open(os.path.join(self.root_dir, self.df.iloc[idx, 1]))  \n",
        "    \n",
        "        if self.transform:\n",
        "            return self.transform(image), self.transform(mask)\n",
        "    \n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1uPurJntwhj"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZFEDbaFt4Yg"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC2xMjuYuZiP"
      },
      "outputs": [],
      "source": [
        "train_samples = ImageDataset(df=train_df, root_dir=TRAIN_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prikaz par slika za treniranje sa identifikovanim nervima.\n"
      ],
      "metadata": {
        "id": "V-jGmEsLJhIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bU6e5UxuvtM"
      },
      "outputs": [],
      "source": [
        "def draw_samples(data, n_col, n_row):\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "        \n",
        "    for i in range(1, n_col + 1):\n",
        "        img_ax = fig.add_subplot(n_row, n_col, i)\n",
        "        msk_ax = fig.add_subplot(n_row, n_col, i + n_col)\n",
        "        \n",
        "        img_ax.imshow(data[i-1][0], cmap='gray')\n",
        "        msk_ax.imshow(data[i-1][1], cmap='gray')\n",
        "        \n",
        "    fig.show()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEdHa_omvNHu"
      },
      "outputs": [],
      "source": [
        " draw_samples(data=train_samples, n_col=7, n_row=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***MODEL*** - deo koji se ƒçuva nakon pokretanja algoritma ma≈°inskog uƒçenja nad podacima za obuƒçavanje i predstavlja odreƒëena pravila koja su neophodna algoritmu za predviƒëanja. Reprezentuje kako da odredjene inpute pretvorimo u outpute.  Postoji lista podr≈æanih kodera u SMP-u, bira se odgovarajuƒáa porodica enkodera i u okviru nje se bira konkretan enkoder koji dolazi sa unapred natreniranim te≈æinama."
      ],
      "metadata": {
        "id": "dQBtqNP8J-tN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coF0qlFWvPMd"
      },
      "outputs": [],
      "source": [
        "ENCODER = 'vgg11_bn'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "ACTIVATION = 'sigmoid'\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHAc6pwv8WOR"
      },
      "outputs": [],
      "source": [
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=1,\n",
        "    classes=1,\n",
        "    activation=ACTIVATION\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciBB-dKY8b4k"
      },
      "outputs": [],
      "source": [
        "loss = smp.utils.losses.DiceLoss()\n",
        "metrics = [smp.utils.metrics.IoU()]\n",
        "optimizer = torch.optim.Adam\n",
        "scheduler = lr_scheduler.StepLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07WZ8Qly8fEV"
      },
      "outputs": [],
      "source": [
        "my_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyEZq7LIhxgD"
      },
      "outputs": [],
      "source": [
        "def split_df(df, fraction=0.8):  \n",
        "    df_1 = df.sample(frac=fraction)\n",
        "    return df_1, df.drop(df_1.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TRENIRANJE MODELA*** - u grubom prevodu znaƒçi da utvrdimo dobre i prave vrednosti za sve tezine iz obole≈æenih i prilo≈æenih primera tj. dataset-a. Na ovaj naƒçin, model se gradi ispitivanjem razliƒçitih primera i poku≈°ajem pronalska modela koji minimizira gubitak.  Poziva se ugraƒëena metoda za zaustavljanje treniranja u sluƒçaju opadanja stope uƒçenja, posle datog patience.\n",
        "Posle uspe≈°nog treniranja ƒçuva se model."
      ],
      "metadata": {
        "id": "u1gZcK8VKYZd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6bjZ73KiO1W"
      },
      "outputs": [],
      "source": [
        "def train(model, train_df, train_dir, optimizer, loss, metrics, \n",
        "          learning_rate=0.01, batch_size=20, epochs=10, patience=3,\n",
        "          scheduler=None, step_size=5, gamma=0.1, device='cpu', transform=None):   \n",
        "    \n",
        "    early_stopping = EarlyStopping(patience, path='best_model.pkl', verbose=True)\n",
        "    optimizer = optimizer(model.parameters(), learning_rate)\n",
        "\n",
        "    if scheduler:\n",
        "        scheduler = scheduler(optimizer, step_size, gamma) \n",
        "\n",
        "    train_epoch = smp.utils.train.TrainEpoch(\n",
        "        model, loss, metrics, optimizer, device, verbose=True\n",
        "    )\n",
        "    \n",
        "    valid_epoch = smp.utils.train.ValidEpoch(\n",
        "        model, loss, metrics, device, verbose=True\n",
        "    ) \n",
        "    \n",
        "    train_logs, valid_logs = [], []\n",
        "    \n",
        "    for epoch in range(epochs):   \n",
        "        train_dataframe, val_dataframe = split_df(train_df) \n",
        "          \n",
        "        train_dataset = ImageDataset(train_dataframe, train_dir, transform=transform)\n",
        "\n",
        "        valid_dataset = ImageDataset(val_dataframe, train_dir, transform=transform)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                                   batch_size=batch_size, \n",
        "                                                   shuffle=True)    \n",
        "\n",
        "        valid_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                                   batch_size=batch_size, \n",
        "                                                   shuffle=False)        \n",
        "\n",
        "        print(f'\\nEpoch: {epoch+1}/{epochs}')\n",
        "\n",
        "        train_log = train_epoch.run(train_loader)\n",
        "        valid_log = valid_epoch.run(valid_loader)\n",
        "        \n",
        "        train_logs.append(train_log)\n",
        "        valid_logs.append(valid_log)\n",
        "   \n",
        "        early_stopping(valid_log[loss.__name__], model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "    return train_logs, valid_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proces treniranja."
      ],
      "metadata": {
        "id": "IvQuFNAVLMo_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apptIq_ciXHJ"
      },
      "outputs": [],
      "source": [
        "res = train(model=model,\n",
        "            train_df=train_df, \n",
        "            train_dir=TRAIN_PATH, \n",
        "            optimizer=optimizer,\n",
        "            loss=loss,\n",
        "            learning_rate=0.01,\n",
        "            metrics=metrics,\n",
        "            batch_size=20,\n",
        "            epochs=20,\n",
        "            scheduler=scheduler,\n",
        "            step_size=10,\n",
        "            patience=3,\n",
        "            device=DEVICE, \n",
        "            transform=my_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUACIJA**\n",
        "\n",
        "Nakon treniranja modela, grafiƒçki se prikazuju rezultati.\n",
        "\n",
        "Prvo je prikazano koliko je bilo preklapanja izmeƒëu predicted i ground truth, izra≈æen u opsegu od 0 do 1, a zatim koliko je bilo odstupanja tokom epoha treniranja.\n",
        "\n"
      ],
      "metadata": {
        "id": "XlgkMqfVLimc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XQQoWXzvnJO"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NOrxL6EvvpA"
      },
      "outputs": [],
      "source": [
        "with open('results.pkl', 'wb') as f:\n",
        "    pickle.dump(res, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c8erQUIwKef"
      },
      "outputs": [],
      "source": [
        "with open('best_model.pkl', 'rb') as f:\n",
        "    best_model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij_TMxM-we5h"
      },
      "outputs": [],
      "source": [
        "train_logs_df = pd.DataFrame(res[0])\n",
        "valid_logs_df = pd.DataFrame(res[1])\n",
        "\n",
        "res_dict = {'train': train_logs_df, 'valid': valid_logs_df}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIjJV9xrw8EW"
      },
      "outputs": [],
      "source": [
        "def draw_graphic(df_dict, title, criteria, xlab, ylab, colors=['b', 'r'], \n",
        "                 legend_loc='best', figsize=(10, 5), fontsize=16):\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    for i, key in enumerate(df_dict):\n",
        "        plt.plot(df_dict[key].index.tolist(), df_dict[key][criteria].tolist(), colors[i], lw=3, label=key)\n",
        "    plt.xlabel(xlab, fontsize=fontsize)\n",
        "    plt.ylabel(ylab, fontsize=fontsize)\n",
        "    plt.title(title, fontsize=fontsize)\n",
        "    plt.legend(loc=legend_loc, fontsize=fontsize)\n",
        "    plt.grid()\n",
        "    fig.show()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGsZTPASxFD8"
      },
      "outputs": [],
      "source": [
        "draw_graphic(df_dict=res_dict, title='IoU Scores', criteria='iou_score', xlab='epochs', ylab='IoU score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu1nX-XUxJIw"
      },
      "outputs": [],
      "source": [
        "draw_graphic(df_dict=res_dict, title='Dice Losses', criteria='dice_loss', xlab='epochs', ylab='IoU score')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTIRANJE**\n",
        "\n",
        "Na kraju se testira model nad test podacima i sve se ƒçuva u submission fajlu.\n",
        "Pravi se submission fajl koji sadr≈æi pretpostavke natreniranog modela. Za svaku sliku iz trening seta se prolazi i pi≈°e kolika je predikcija odnosno gde je predviƒëeno da se nalazi nerv."
      ],
      "metadata": {
        "id": "JBvwl1lpLusz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Jm7k5gAxODs"
      },
      "outputs": [],
      "source": [
        "def rle_encoding(x):\n",
        "    dots = np.where(x.T.flatten()==1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b+1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s_JgGXExWfi"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PKxs816xZZL"
      },
      "outputs": [],
      "source": [
        "imgs = [f for f in os.listdir(TEST_PATH)]\n",
        "imgs = sorted(imgs, key=lambda s: int(s.split('.')[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEd_zn4exbcg"
      },
      "outputs": [],
      "source": [
        "def create_csv_submission(model, data_path, img_list, out_path):\n",
        "    submission_df = pd.DataFrame(columns=['img', 'pixels'])\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    \n",
        "    for i, img in enumerate(tqdm(img_list)):\n",
        "        x = Image.open(os.path.join(data_path, img))\n",
        "\n",
        "        x = my_transforms(x)\n",
        "\n",
        "        x = x.unsqueeze(0).to(DEVICE)\n",
        "        pred_mask = model.predict(x)\n",
        "\n",
        "        pred_mask = pred_mask.cpu()#.numpy().round().astype(np.uint8)\n",
        "        pred_mask = transforms.Resize(size=(420, 580))(pred_mask)\n",
        "\n",
        "        encoding = rle_encoding(pred_mask)\n",
        "\n",
        "        pixels = ' '.join(map(str, encoding))\n",
        "        submission_df.loc[i] = [str(i+1), pixels]\n",
        "\n",
        "    submission_df.to_csv(out_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLlfmo10xibU"
      },
      "outputs": [],
      "source": [
        "create_csv_submission(model=model, \n",
        "                      data_path=TEST_PATH, \n",
        "                      img_list=imgs,\n",
        "                      out_path='submission.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "it50_2018_stanƒçiƒá_lena_segmentacija.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9Xr3HC9CDctFMhXWzHHBK",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}